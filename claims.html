<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>Claims - The Creator Project</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
<script src="js/header.js"></script>

<main>
    <h1>Claims</h1>
    <p>Use the navigation above to explore our content.</p>

    <div class="claim-section">
        <h2 id="claim1" class="claim-header">Claim 1: War Should Not Be Automated by AI</h2>
        <p class="claim-statement">Human judgment and accountability should remain at the center of decisions which cost
            human lives.</p>
        <ul>
            <li>There should be regulations on automation within the military.</li>
            <li>Human lives should not be separated from war.</li>
            <li>Military personnel and government officials should still be directly connected to conflicts and warfare
                decisions.
            </li>
        </ul>
    </div>
    <div>
        <h2 id="claim2" class="claim-header">Claim 2: Targeting Systems Should Minimize Civilian Casualties</h2>
        <p class="claim-statement">Collateral damage must be reduced by requiring AI and military targeting systems to
            prioritize the safety of
            civilians.</p>
        <ul>
            <li>There were significant civilian casualties in Syria due to airstrikes.</li>
            <li>In 2019, U.S. and Afghan air forces were leading causes of civilian deaths.</li>
        </ul>
        <div class="sources-box" id="sources2">
            <h3>Sources:</h3>
            <ul class="source-list">
                <li>
                    <a href="https://www.wsj.com/articles/hard-questions-in-syria-about-the-civilian-toll-of-u-s-strategy-11564769734?mod=Searchresults_pos3&page=1"
                       target="_blank">Hard Questions in Syria About the Civilian Toll of U.S. Strategy</a></li>
                <li>
                    <a href="https://www.wsj.com/articles/afghan-and-u-s-forces-not-taliban-killed-more-civilians-this-year-11556120667?mod=Searchresults_pos12&page=1"
                       target="_blank">Afghan and U.S. Forces, Not Taliban, Killed More Civilians This Year</a></li>
                <li>
                    <a href="https://link.springer.com/article/10.1007/s11229-023-04189-0#:~:text=This%20paper%20examines%20racial%20discrimination,given%20in%20the%20bias%20reduction"
                       target="_blank">Predictive policing and algorithmic fairness | Synthese</a></li>
            </ul>
        </div>
    </div>
    <div>
        <h2 id="claim3" class="claim-header">Claim 3: AI Use of Faces, Memories, and Identities Without Permission is a
            Serious Invasion of
            Privacy</h2>
        <p class="claim-statement">The copying and use of memories, brain data, and identities,even after death, raises
            deep ethical concerns
            about privacy and consent.</p>
        <ul>
            <li>New brain scanning technologies and brain-computer interfaces are being developed, such as Neuralink.
            </li>
            <li>Neuroscientists have outlined methods to theoretically upload a person’s mind into computers, requiring
                both scans and hardware to store consciousness.
            </li>
        </ul>
        <div class="sources-box" id="sources3">
            <h3>Sources:</h3>
            <ul class="source-list">
                <li>
                    <a href="https://www.wsj.com/articles/elon-musks-neuralink-advances-brain-computer-interface-11563334987?mod=Searchresults_pos1&page=1"
                       target="_blank">Elon Musk's Neuralink Advances Brain-Computer Interface</a></li>
                <li>
                    <a href="https://www.wsj.com/articles/the-machines-that-will-read-your-mind-11554476156?mod=Searchresults_pos3&page=1"
                       target="_blank">The Machines That Will Read Your Mind</a></li>
                <li>
                    <a href="https://www.wsj.com/articles/will-your-uploaded-mind-still-be-you-11568386410?mod=Searchresults_pos8&page=1"
                       target="_blank">Will Your Uploaded Mind Still Be You?</a></li>
                <li><a href="https://www.scbc-law.org/post/keeping-the-dead-alive-ai-grief-bots-and-privacy-concerns"
                       target="_blank">Keeping the Dead Alive: AI Grief Bots and Privacy Concerns</a></li>
                <ul class="source-description">
                    The article examines AI grief bots that simulate deceased individuals, similar to the film's
                    simulants
                    carrying the memories of real people. It highlights the privacy issues and emotional ramifications
                    of
                    interacting with AI representations of the dead, especially without explicit consent.
                    <ul>
                        <li>Companies use social media and available materials to create an AI chatbot modeled to imitate the deceased</li>
                        <li>No control over what the bot says—it’s not the real thoughts, beliefs, or words of the person, just a simulation based on available data</li>
                        <li>No clear legal protections outside user agreements, as privacy does not extend post-mortem</li>
                        <li>Right to publicity depends on whether it's treated as a privacy right or a property right</li>
                        <li>In <em>The Creator</em>, personas are transferred from the dead into simulants without consent to extract information—similar to grief bots simulating the person with their memories and mannerisms</li>
                        <li>External motives: profit in real life, intelligence gathering in the film</li>
                    </ul>
                </ul>
                <li>
                    <a href="https://www.the-independent.com/arts-entertainment/films/news/star-wars-peter-cushing-estate-lawsuit-b2611483.html#:~:text=Lucasfilms%20have%20protested%20the%20case,the%20use%20of%20his%20appearance.">Star
                        Wars movie sued for digital recreation of Peter Cushing’s appearance</a></li>
                <ul class="source-description">
                    The lawsuit over the unauthorized digital resurrection of actor Peter Cushing in "Rogue One"
                    reflects
                    real-world legal challenges concerning the use of a person's likeness posthumously. This parallels
                    the
                    film's depiction of simulants created in the image of real individuals, emphasizing the need for
                    clear
                    consent and ethical guidelines.
                    <ul>
                        <li>Digitally recreated likeness for a film</li>
                        <li>No consent given before death</li>
                        <li>Lawsuit unresolved but could have big implications</li>
                        <li>In <em>The Creator</em>, simulants are created with the likeness of real humans</li>
                        <li>The likeness can be consensually donated in the film’s universe, but it’s still at the mercy of others’ decisions—similar to how Cushing had no say in how his image was used after death</li>
                        <li>Maya’s likeness was used by the U.S. government in a fake video showing her alive and well, even though she was in a coma</li>
                    </ul>
                </ul>
                <li>
                    <a href="https://www.slashfilm.com/1789940/the-simpsons-voice-actor-hank-azaria-ai-replacement-test/">A
                        Simpsons Voice Actor Tested Out His AI Replacement And It Didn't Go Well</a></li>
                <ul class="source-description">
                    This piece highlights the complexities and potential pitfalls of using AI to replicate human voices,
                    as
                    experienced by voice actor Hank Azaria. In the film, the creation of simulants with human-like
                    attributes
                    raises similar concerns about authenticity, consent, and the potential for AI to misrepresent or
                    replace
                    real individuals without their approval.
                    <ul>
                        <li>Voice actors are facing the threat of being replaced by AI trained to sound like them</li>
                        <li>Actors like Azaria believe AI can't capture the emotion and craft of a real performance</li>
                        <li>SAG has made deals with AI companies allowing actors to license digital voice replicas, setting a potentially dangerous precedent</li>
                        <li>Concerns that actors may be forced to license their voice for a role and lose control of it—especially after death</li>
                        <li>Azaria notes that viewers may not care if a voice is AI-generated as long as it sounds good, which increases the risk</li>
                        <li>James Earl Jones licensed his voice before retirement</li>
                        <li>Likeness becomes a reusable asset</li>
                        <li>Scarlett Johansson’s voice was reportedly used for an AI assistant without her consent</li>
                        <li>AI can only mimic a person, not truly capture them</li>
                    </ul>
                </ul>
            </ul>
        </div>
    </div>
    <br>
    <br>
    <br>
    <div>
        <h2>Additional Context: Use of Robotics and AI in Military and Law Enforcement</h2>
        <p>Excerpt from discussion:</p>
        <blockquote>
            The film <i>The Creator</i> reflects many of today's struggles to agree on AI governance, and the ethical
            concerns of AI-driven warfare. In the film, where AI has gained sentience, Asia embraces AI while the U.S.
            bans
            it due to perceived threats. This mirrors real-world struggles to govern AI, requiring international
            cooperation
            between governments, corporations, and the public. The automation of warfare and the militarization of AI
            could
            save lives but raises concerns about global security and the possibility of an AI arms race. Regulation is
            increasingly difficult as AI development advances, highlighting the need for ethical guidelines and
            policies.
        </blockquote>
        <div class="sources-box">
            <h3>Sources:</h3>
            <ul class="source-list">
                <li>
                    <a href="https://unu.edu/article/militarization-ai-has-severe-implications-global-security-and-warfare"
                       target="_blank">Militarization of AI Has Severe Implications for Global Security and Warfare |
                        United
                        Nations University</a></li>
                <li>
                    <a href="https://carnegieendowment.org/research/2024/08/understanding-the-global-debate-on-lethal-autonomous-weapons-systems-an-indian-perspective?center=india&lang=en"
                       target="_blank">Understanding the Global Debate on Lethal Autonomous Weapons Systems | Carnegie
                        Endowment
                        for International Peace</a></li>
            </ul>
        </div>
    </div>
</main>
</body>
</html>
